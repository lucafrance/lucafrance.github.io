---
title: AI safety for fleshy humans by Nicky Case
tags: [AI]
---

Title? AI safety matters because humanity matters.

TL, DR: Nicky Case [explains well](https://aisafety.dance) why you should care about AI safety.

- Nicky Case recently released the last part of her AI safety series.
- I enjoyed how it was structured.
- AI safety is both a human and technological problem.
    - https://aisafety.dance/media/p3/intro/breakdown.png
    - Humans need to agree on what they want in general.
        - Use of any tool, including AI, is in function of that.
    - https://aisafety.dance/media/p3/SUM.png
    - The technological problem of ensuring the AI does what we want depends on that.
- AI safety used to be a theoretical exercise about the AGI control problem.
    - Nick Bostrom wrote about in 2014 in the book *Superintelligence: Paths, Dangers, Strategies*.
- With the rise of LLM it is no longer a theoretical exercise.
    - [Robert Miles -  AI Ruined My Year](https://www.youtube.com/watch?v=2ziuPUeewK0)
- We see now ways where AI can be dangerous.
    - TODO studio AI su cui Robert Miles ha fatto anche un video in cui la LLM attivamente cerca di ingannare l'utente
    - TODO Demo (di Palanatir?) per una AI per comando di attacchi militari. Veniva menzionato credo nel video di ordinary things sui droni.
- There is no silver bullet.
    - AI alignment should keep outgroving AI capabilities.
    - It is here and we need to deal with it.
    - https://aisafety.dance/media/p1/Rocket%202.png
    - https://aisafety.dance/media/p3/governance/rocket.png
- I like the optimism of the series.
    - The existence of artificial intelligence does not mean we need to give up our human intelligence.
