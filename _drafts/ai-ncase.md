---
title: AI safety for fleshy humans by Nicky Case
tags: []
---

TL, DR: Nicky Case [explains well](https://aisafety.dance) why you should care about AI safety.

Nicky Case recently released the last part of her AI safety series.

I recommend it.

Nick Bostrom wrote about in 2014 in the book *Superintelligence: Paths, Dangers, Strategies*.

It is a great introduction to the control problem of AGI.
With advance of LLM is less abstract topic.
We see LLM starting deceiving in ways that were theorised in the past.
TODO example

As mentioned by Robert Miles, now is the time to act.
[Robert Miles -  AI Ruined My Year](https://www.youtube.com/watch?v=2ziuPUeewK0)

As capabilities increase, so should alignment techniques.
https://aisafety.dance/media/p3/governance/rocket.png


I enjoyed how it was structured.
- AI is a tool, and it only matters when used by humans.
- AI safety is both a human and a technical problem.
    - AI safety is also about human policy and reasoning about human values.
- There is reason to be optimistic and to be careful.
- Imperfect solutions are a good starting point, even if we don't have a perfect one yet.


https://aisafety.dance/media/p3/intro/breakdown.png

https://aisafety.dance/media/p3/SUM.png

