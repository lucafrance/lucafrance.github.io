---
title: AI safety for fleshy humans by Nicky Case
tags: [AI]
---

Title? AI safety matters because humanity matters.

TL, DR: Nicky Case [explains well](https://aisafety.dance) why you should care about AI safety.

- Nicky Case recently released the last part of her AI safety series.
- I enjoyed how it was structured.
- AI safety is both a human and technological problem.
    - https://aisafety.dance/media/p3/intro/breakdown.png
    - Humans need to agree on what they want in general.
        - Use of any tool, including AI, is in function of that.
    - The technological problem of ensuring the AI does what we want depends on that.
-Even if humanity never achieves AGI, we can see the potential damage right now.
    - technological problem TODO tecnologia studio AI su cui Robert Miles ha fatto anche un video in cui la LLM attivamente cerca di ingannare l'utente
    - human problem: TODO human: Demo (di Palanatir?) per una AI per comando di attacchi militari. Veniva menzionato credo nel video di ordinary things sui droni.


> A note of pessimism, followed by cautious optimism.
> 
Consider the last few decades in politics. Covid-19, the fertility crisis, the opioid crisis, global warming, more war? "Humans coordinating to deal with global threats" is... not a thing we seem to be > good at.
> 
> But we used to be good at it! We eradicated smallpox[83], it's no longer the case that half of kids died before age 15[84], the ozone layer is actually > healing! [85]
> 
> Humans have solved the "human alignment problem" before.
> 
> Let's get our groove back, and align ourselves on aligning AI.

# materiale tagliato

- https://aisafety.dance/media/p3/SUM.png

AI Safety used to be a theoretical exercise about the control problem for potential Artificial General Intelligence (AGI)[^nbostrom-superintelligence].
The rise of LLMs turned AI safety in a current concern[^rmiles-AI-ruined].

[^nbostrom-superintelligence]: A great book about the AI control problem is [*Superintelligence* by Nick Bostrom (2014)](https://global.oup.com/academic/product/superintelligence-9780199678112?cc=de&lang=en&)

[^rmiles-AI-ruined]: For a very honest take about the change of perspective on AI research, I recommend the Youtube video [*AI Ruined My Year* by Robert Miles](https://www.youtube.com/watch?v=2ziuPUeewK0).

- There is no silver bullet.
    - AI alignment should keep outgroving AI capabilities.
    - It is here and we need to deal with it.
    - https://aisafety.dance/media/p1/Rocket%202.png
- I like the optimism of the series.
    - https://aisafety.dance/media/p3/governance/rocket.png
    - The existence of artificial intelligence does not mean we need to give up our human intelligence.
